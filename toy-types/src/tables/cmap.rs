use crate::*;
use zerocopy::{AsBytes, FromBytes, LayoutVerified, Unaligned, BE, I16, U16};

#[derive(Clone, Debug, FontThing)]
pub struct Cmap<'a> {
    pub version: uint16,
    pub num_tables: uint16,
    #[font_thing(count = "num_tables")]
    pub encoding_records: Array<'a, EncodingRecord>,
    #[font_thing(data)]
    data: Blob<'a>,
}

#[derive(Clone, Debug, FontThing)]
pub struct EncodingRecord {
    pub platform_id: uint16,
    pub encoding_id: uint16,
    pub subtable_offset: Offset32,
}

/// A 'concrete' Cmap4 type
#[derive(Clone, Debug, FontThing)]
pub struct Cmap4<'a> {
    pub format: uint16,
    pub length: uint16,
    pub language: uint16,
    pub seg_count_x2: uint16,
    pub search_range: uint16,
    pub entry_selector: uint16,
    pub range_shift: uint16,
    #[font_thing(count(fn = "div_by_two", args("seg_count_x2")))]
    pub end_code: Array<'a, uint16>,
    pub reserved_pad: uint16,
    #[font_thing(count(fn = "div_by_two", args("seg_count_x2")))]
    pub start_code: Array<'a, uint16>,
    #[font_thing(count(fn = "div_by_two", args("seg_count_x2")))]
    pub id_delta: Array<'a, int16>,
    #[font_thing(count(fn = "div_by_two", args("seg_count_x2")))]
    pub id_range_offsets: Array<'a, uint16>,
    #[font_thing(all)]
    glyph_id_array: Array<'a, uint16>,
}

fn div_by_two(seg_count_x2: uint16) -> uint16 {
    seg_count_x2 / 2
}

/// A dummy version of cmap format 6.
///
/// We only have this so we can test out generating an enum from an inline tag.
#[derive(Clone, Debug, FontThing)]
pub struct Cmap6 {
    pub format: uint16,
    pub length: uint16,
    pub language: uint16,
    pub first_code: uint16,
    pub entry_count: uint16,
}

/// A proof-of-concept of a generated enum.
#[derive(Clone, Debug, FontThing)]
// format() attribute is for specifying the type of the version number, assumed
// to be at the start of the buffer.
#[font_thing(format(uint16))]
pub enum CmapSubtable<'a> {
    #[font_thing(format = 4)] // this variant will be created if this format # is parsed
    Format4(Cmap4<'a>),
    #[font_thing(format = 6)]
    Format6(Cmap6),
}

/// A Cmap4 type using zerocopy.
///
/// This is all hand-written, and is intended as a proof-of-concept to get a feel
/// for what the API is like.
pub struct Cmap4Zero<'a> {
    pub header: &'a Cmap4ZeroHeader,
    data: &'a [u8],
}

impl Cmap4Zero<'_> {
    /// only exists so we can check what asm is being generated
    pub fn length(&self) -> u16 {
        self.header.length.get()
    }
}

/// A Cmap4 type using zerocopy, which does bounds checking etc ahead of time
///
/// This is all hand-written, and is intended as a proof-of-concept to get a feel
/// for what the API is like.
pub struct Cmap4ZeroChecked<'a> {
    pub header: &'a Cmap4ZeroHeader,
    end_code: &'a [U16<BE>],
    _reserved_pad: U16<BE>,
    start_code: &'a [U16<BE>],
    id_delta: &'a [I16<BE>],
    id_range_offsets: &'a [U16<BE>],
    glyph_id_array: &'a [U16<BE>],
}

#[derive(FromBytes, AsBytes, Unaligned)]
#[repr(C)]
pub struct Cmap4ZeroHeader {
    pub format: U16<BE>,
    pub length: U16<BE>,
    pub language: U16<BE>,
    pub seg_count_x2: U16<BE>,
    pub search_range: U16<BE>,
    pub entry_selector: U16<BE>,
    pub range_shift: U16<BE>,
}

impl<'a> Cmap4Zero<'a> {
    fn new(bytes: &'a [u8]) -> Option<Self> {
        let (header, data) = LayoutVerified::<_, Cmap4ZeroHeader>::new_from_prefix(bytes)?;
        let n_segments = header.seg_count_x2.get() / 2;
        let table_len = n_segments as usize * std::mem::size_of::<u16>() * 4; // 4 tables
        let padding_len = std::mem::size_of::<u16>();
        if data.len() < table_len + padding_len {
            None
        } else {
            Some(Cmap4Zero {
                header: header.into_ref(),
                data,
            })
        }
    }

    #[inline]
    fn segment_len_bytes(&self) -> usize {
        self.header.seg_count_x2.get() as usize
    }

    /// gets one of the four segment arrays.
    ///
    /// Pass the initial offset of the array, and the length in bytes
    ///
    /// # Safety:
    ///
    /// start + len *must* be in the range of values checked at construction time.
    /// in practice we expect this to be generated by a macro?
    fn get_raw_seg_array<T: FromBytes + Unaligned>(
        &self,
        start: usize,
        len_bytes: usize,
    ) -> &'a [T] {
        debug_assert!(self.data.get(start..start + len_bytes).is_some());
        let table = self.data.get(start..start + len_bytes).unwrap();
        LayoutVerified::new_slice_unaligned(table)
            .unwrap()
            .into_slice()
    }

    fn end_code(&self) -> &'a [U16<BE>] {
        let table_len = self.segment_len_bytes();
        self.get_raw_seg_array(0, table_len)
    }

    fn start_code(&self) -> &'a [U16<BE>] {
        let table_len = self.segment_len_bytes();
        let start = table_len + std::mem::size_of::<U16<BE>>(); // end_table + reserved field
        self.get_raw_seg_array(start, table_len)
    }

    fn id_delta(&self) -> &'a [I16<BE>] {
        let table_len = self.segment_len_bytes();
        let start = table_len * 2 + std::mem::size_of::<U16<BE>>(); // end_code + start_code + reserved field
        self.get_raw_seg_array(start, table_len)
    }

    fn id_range_offsets(&self) -> &'a [U16<BE>] {
        let table_len = self.segment_len_bytes();
        let start = table_len * 3 + std::mem::size_of::<U16<BE>>(); // end_code + start_code + id_delta + reserved field
        self.get_raw_seg_array(start, table_len)
    }

    fn glyph_id_array(&self) -> &'a [U16<BE>] {
        let table_len = self.segment_len_bytes();
        let start = table_len * 4 + std::mem::size_of::<U16<BE>>();
        // this is variable length. we could be fancy in various ways, but being safe is cool
        let table = self.data.get(start..).unwrap_or_default();
        LayoutVerified::new_slice_unaligned(table)
            .unwrap()
            .into_slice()
    }

    pub fn glyph_id_for_char(&self, chr: char) -> uint16 {
        let n_segs = self.header.seg_count_x2.get() / 2;
        let raw_char = (chr as u32).try_into().unwrap_or_default();
        let seg_idx = match self
            .end_code()
            .binary_search_by(|probe| probe.get().cmp(&raw_char))
        {
            Ok(idx) => idx,
            Err(idx) => idx,
        };

        // safety: `seg_idx` must be < end_code.len(), and all arrays have equal length;
        // therefore the index must be valid in all of them.
        let start_code = unsafe { self.start_code().get_unchecked(seg_idx).get() };
        // TODO: get rid of this branch?
        if start_code > raw_char {
            return 0;
        }
        let id_delta = unsafe { self.id_delta().get_unchecked(seg_idx).get() };
        let range_offset = unsafe { self.id_range_offsets().get_unchecked(seg_idx).get() / 2 };
        let glyf_idx = if range_offset == 0 {
            wrapping_add_delta(raw_char, id_delta)
        } else {
            let offset_rel_id_range = range_offset + (raw_char - start_code);
            let glyf_idx = offset_rel_id_range - (n_segs - seg_idx as u16);
            if glyf_idx != 0 {
                wrapping_add_delta(glyf_idx, id_delta)
            } else {
                0
            }
        };

        self.glyph_id_array()
            .get(glyf_idx as usize)
            .map(|val| val.get())
            .unwrap_or_default()
    }
}

impl<'a> Cmap4ZeroChecked<'a> {
    fn new(bytes: &'a [u8]) -> Option<Self> {
        fn make_slice<T: FromBytes + Unaligned>(raw: &[u8]) -> Option<&[T]> {
            LayoutVerified::new_slice_unaligned(raw).map(|lv| lv.into_slice())
        }

        let (header, data) = LayoutVerified::<_, Cmap4ZeroHeader>::new_from_prefix(bytes)?;
        let header = header.into_ref();
        let seg_len_bytes = header.seg_count_x2.get() as usize;
        let padding_len = std::mem::size_of::<u16>();
        let end_code = data.get(..seg_len_bytes).and_then(make_slice)?;
        let start_code = data
            .get(seg_len_bytes + padding_len..)
            .and_then(make_slice)?;
        let id_delta = data
            .get(seg_len_bytes * 2 + padding_len..)
            .and_then(make_slice)?;
        let id_range_offsets = data
            .get(seg_len_bytes * 3 + padding_len..)
            .and_then(make_slice)?;
        let glyph_id_array = data
            .get(seg_len_bytes * 4 + padding_len..)
            .and_then(make_slice)?;
        Some(Self {
            header,
            end_code,
            start_code,
            id_delta,
            id_range_offsets,
            _reserved_pad: 2.into(),
            glyph_id_array,
        })
    }

    pub fn glyph_id_for_char(&self, chr: char) -> uint16 {
        let n_segs = self.header.seg_count_x2.get() / 2;
        let raw_char = (chr as u32).try_into().unwrap_or_default();
        let seg_idx = match self
            .end_code
            .binary_search_by(|probe| probe.get().cmp(&raw_char))
        {
            Ok(idx) => idx,
            Err(idx) => idx,
        };

        // safety: `seg_idx` must be < end_code.len(), and all arrays have equal length;
        // therefore the index must be valid in all of them.
        let start_code = unsafe { self.start_code.get_unchecked(seg_idx).get() };
        // TODO: get rid of this branch?
        if start_code > raw_char {
            return 0;
        }
        let id_delta = unsafe { self.id_delta.get_unchecked(seg_idx).get() };
        let range_offset = unsafe { self.id_range_offsets.get_unchecked(seg_idx).get() / 2 };
        let glyf_idx = if range_offset == 0 {
            wrapping_add_delta(raw_char, id_delta)
        } else {
            let offset_rel_id_range = range_offset + (raw_char - start_code);
            let glyf_idx = offset_rel_id_range - (n_segs - seg_idx as u16);
            if glyf_idx != 0 {
                wrapping_add_delta(glyf_idx, id_delta)
            } else {
                0
            }
        };

        self.glyph_id_array
            .get(glyf_idx as usize)
            .map(|val| val.get())
            .unwrap_or_default()
    }
}

impl<'a> Cmap<'a> {
    pub fn get_subtable_version(&self, offset: Offset32) -> Option<u16> {
        self.data.read(offset as usize)
    }

    pub fn subtable(&self, offset: Offset32) -> Option<CmapSubtable> {
        self.data
            .get(offset as usize..self.data.len())
            .and_then(FontRead::read)
    }

    /// Get the subtable at the given offset and attempt to interpret it as `T`
    pub fn parse_subtable<T: FontRead<'a>>(&self, offset: Offset32) -> Option<T> {
        self.data
            .get(offset as usize..self.data.len())
            .and_then(T::read)
    }

    pub fn get_zerocopy_cmap4(&self, offset: Offset32) -> Option<Cmap4Zero> {
        self.data
            .get(offset as usize..self.data.len())
            .and_then(|data| Cmap4Zero::new(data.as_bytes()))
    }

    pub fn get_zerocopy_cmap4_precheck(&self, offset: Offset32) -> Option<Cmap4ZeroChecked> {
        self.data
            .get(offset as usize..self.data.len())
            .and_then(|data| Cmap4ZeroChecked::new(data.as_bytes()))
    }
}

impl<'a> Cmap4<'a> {
    /// Find a glyphid, maybe
    ///
    /// Each segment is described by a startCode and endCode, along with an idDelta
    /// and an idRangeOffset, which are used for mapping the character codes in
    /// the segment. The segments are sorted in order of increasing endCode values,
    /// and the segment values are specified in four parallel arrays. You search
    /// for the first endCode that is greater than or equal to the character code
    /// you want to map. If the corresponding startCode is less than or equal to the
    /// character code, then you use the corresponding idDelta and idRangeOffset
    /// to map the character code to a glyph index (otherwise, the missingGlyph
    /// is returned). For the search to terminate, the final start code and endCode
    /// values must be 0xFFFF. This segment need not contain any valid mappings.
    /// (It can just map the single character code 0xFFFF to missingGlyph).
    /// However, the segment must be present.
    pub fn glyph_id_for_char(&self, chr: char) -> uint16 {
        //NOTE: this impl is bad
        let raw_char = (chr as u32).try_into().unwrap_or(0_u16);
        let end_code_idx = match self.end_code.binary_search(&raw_char) {
            Ok(idx) => idx,
            Err(idx) => idx,
        };
        let start_code = self.start_code.get(end_code_idx).unwrap();
        if start_code > raw_char {
            return 0;
        }

        let id_delta = self.id_delta.get(end_code_idx).unwrap();
        // stored in bytes, convert to index (u16 == two bytes)
        let range_offset = self.id_range_offsets.get(end_code_idx).unwrap() / 2;
        let range_array_len = self.id_range_offsets.len() as u16;
        let glyf_idx: u16 = if range_offset != 0 {
            // this is the offset relative to our position in
            // id_range_offsets, e.g. we're supposed to do ptr::add from
            // the position corresponding to id_range_offsets[idx].
            // in practice this means we need to add the # of items > idx in
            // order to figure out the position relative to the glyph array.
            let offset_rel_id_range = range_offset + (raw_char - start_code);
            let glyf_idx = offset_rel_id_range - (range_array_len - end_code_idx as u16);
            if glyf_idx != 0 {
                wrapping_add_delta(glyf_idx, id_delta)
            } else {
                0
            }
        } else {
            wrapping_add_delta(raw_char, id_delta)
        };
        self.glyph_id_array
            .get(glyf_idx as usize)
            .unwrap_or_default()
    }
}

#[inline(always)]
pub fn wrapping_add_delta(base: u16, delta: i16) -> u16 {
    let r: u32 = (base as i32 + delta as i32).max(0) as u32;
    (r % 0xFFFF) as u16
}
